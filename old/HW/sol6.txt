Due on 11/30, submit in hard copy

Chapter 5

9. (15%)
[a] direct mapped where data in cache is located by its associated block address
in memory (using the "tag" portion of the block), set associative where cache is divided
into sets into which multiple blocks can be placed (blocks are located according to an
index field that maps into a cache's particular set), and full associative where blocks are
placed anywhere in cache, and must be located by searching the entire cache every time.
[b] When the CPU wants to read data from memory, level-1 cache is checked first to
determine if that data is in residence there. If the data is in level-1 cache, this result is
called a cache hit. The located data is then returned to the CPU and the memory access
process is complete. If the data is not located in level-1 cache, it is called cache miss.

10. (15%)
1) Optimal, using future reference time, swapping out pages that won't be
used in the near future. 2) FIFO (First-In-First-Out) is another scheme, which as its name
implies, swaps out the pages that are the oldest (regardless of how often it is accessed) in
the system. While a simpler algorithm then LRU, FIFO is the much less efficient.
3) Least Recently Used (LRU), which swaps out pages that were used the least recently.

Chapter 9

2. (10%)
[a] The kernel is a component that contains the main functionality of the OS
[b] i.e., 1) Process Management. How the OS manages and views other software in the
embedded system. 2) Memory Management. The embedded system's memory space is
shared by all the different processes, thus access and allocation of portions of the memory
space need to be managed......

7. (15%)
[a] 1) Ready : The process is ready to be executed at anytime, but is waiting for
permission to use the CPU. 2) Running : The process has been given permission to use
the CPU, and can execute. 3) Blocked or Waiting: The process is waiting for some
external event to occur before it can be "ready" to "run".
[b] Any examples shown in text or taken from OS vendor documentation

9. (10%)
[a] An OS in which tasks always meet their deadlines, and related execution times are
predictable (deterministic).
[b] any from text or current OS vendors i.e., vxWorks, Nucleus, Jbed RTOS, etc.

11. (10%)
The shared data (memory sharing) model are where processes communicate via
access to shared areas of memory in which variables modified by one process is
accessible to all processes. Intertask communication via message passing is an algorithm
in which messages (made up of data bits) are sent via message queues between
processes. Finally, signals are indicators to a task that an asynchronous event has been
generated by some external event (i.e. other processes, hardware on the board, timers,
etc.) or some internal event (i.e. problems with the instructions being executed, etc.) .

15. (10%)
[a] Segmentation is where a process encapsulates all the information that is involved in
executing a program, including source code, stack, data, and so on and all of the different
types of information within a process are divided into "logical" memory units of variable
sizes, called segments.
[b] Segment addresses are logical addresses that start at 0, and are made up of a segment
number (which indicates the base address of the segment) and a segment offset (defines
the actual physical memory address).
[c] Most OSes typically will allow processes to have all or some combination of 5 types
of information within segments, such as text (or code) segment, data segment , bss
segment , stack segment, and the heap segment.

17. (15%)
[a] Paging is where an OS divides logical memory into some number of fixed-size
partitions called pages, and these pages are swapped in and out of memory as needed to
create the illusion of a larger memory space.
[b] i.e., 1) Optimal, using future reference time, swapping out pages that won't be used in
the near future. 2) FIFO (First-In-First-Out) is another scheme, which as its name implies,
swaps out the pages that are the oldest (regardless of how often it is accessed) in the
system. While a simpler algorithm then LRU, FIFO is the much less efficient. 3) Least
Recently Used (LRU), which swaps out pages that were used the least recently.
4) Not Recently Used (NRU), swaps out pages that were not used within a certain time
period.


